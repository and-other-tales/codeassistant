# LLM API Keys (at least one is required)
#OPENAI_API_KEY=
#ANTHROPIC_API_KEY=

# GROQ API Key for Groq LLM support
GROQ_API_KEY=

# LLM model selection (override default Anthropic with Groq or any other provider)
CODE_GEN_MODEL=groq/meta-llama/llama-4-scout-17b-16e-instruct
REFLECTION_MODEL=groq/meta-llama/llama-4-scout-17b-16e-instruct

# Vector database configuration (Pinecone is default, MongoDB is optional)
PINECONE_API_KEY=
PINECONE_INDEX_NAME=codeassistant

# Optional MongoDB configuration (if using MongoDB as retriever)
MONGODB_URI=

# Application configuration
PORT=8080
HOST=0.0.0.0

# LangChain tracing and project configuration
LANGCHAIN_TRACING=true
LANGCHAIN_ENDPOINT=https://api.smith.langchain.com
LANGCHAIN_API_KEY=
LANGCHAIN_PROJECT=codeassistant